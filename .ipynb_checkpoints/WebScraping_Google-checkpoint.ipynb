{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85de7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import selenium\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a8b95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating function for scrapping images from google\n",
    "def images(item):\n",
    "    # load the driver and url\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://images.google.com/?gws_rd=ssl')\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # entering the input in search bar and clicking the search button  \n",
    "    search = driver.find_element(By.TAG_NAME,\"input\").send_keys(item)\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.XPATH,'//span[@class=\"z1asCe MZy1Rb\"]').click()\n",
    "   \n",
    "\n",
    "    print(\"start scrolling to generate more images on the page...\")\n",
    "    # we scroll down in order to generate more images on the website\n",
    "    for _ in range(1000):\n",
    "        driver.execute_script(\"window.scrollBy(0,10000)\")\n",
    "    \n",
    "    # saving the path\n",
    "    images=driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "    # create empty lists\n",
    "    image_url=[]\n",
    "    image_data=[]\n",
    "    # iterating\n",
    "    for image in images:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "            if(source[0:4] =='http'):\n",
    "                image_url.append(source)\n",
    "            \n",
    "    # now specify the file location and then download the image \n",
    "    print(\"Downloading ...\")\n",
    "    for i in range(len(image_url)):\n",
    "        if i>=100:\n",
    "            break\n",
    "        print(\"- {0} of {1} images\" .format(i, 100),end=\"\\n\")\n",
    "        response =requests.get(image_url[i])\n",
    "        file =open(r\"/home/sparkbrains/Documents/Web Scraping_\"+str(i)+\".jpg\",\"wb\")\n",
    "        file.write(response.content)\n",
    "    print(\"\\n\",20*\" *\",\" Downloaded \",20*\" *\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5252cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function finding the result\n",
    "images('cars')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a356f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
